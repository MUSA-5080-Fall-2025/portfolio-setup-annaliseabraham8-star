---
title: "Lab Assignment 4: Spatial Predictive Analysis"
subtitle: "MUSA 5080 - Fall 2025"
author: "Annalise Abraham"
date: today
format:
  html:
    code-fold: show
    code-tools: true
    toc: true
    toc-depth: 3
    toc-location: left
    theme: cosmo
    embed-resources: true
editor: visual
execute:
  warning: false
  message: false
---

# Table of Contents

## *Introduction*

## *Part 1: Data Loading and Exploration*

## *Part 2: Fishnet Grid Creation*

## *Part 3: Spatial Features*

## *Part 4: Count Regression Models*

## *Part 5: Spatial Cross Validation*

## *Part 6: Model Evaluation*

# Introduction

## Assignment Overview

In this lab I will use spatial modeling techniques and 311 service requests -for alleys with one or more lights out- to predict the locations of burglaries in the city of Chicago.

## Setup

```{r setup}
#| message: false
#| warning: false

# Load required packages
library(tidyverse)      # Data manipulation
library(sf)             # Spatial operations
library(here)           # Relative file paths
library(viridis)        # Color scales
library(terra)          # Raster operations (replaces 'raster')
library(spdep)          # Spatial dependence
library(FNN)            # Fast nearest neighbors
library(MASS)           # Negative binomial regression
library(patchwork)      # Plot composition (replaces grid/gridExtra)
library(knitr)          # Tables
library(kableExtra)     # Table formatting
library(classInt)       # Classification intervals
library(here)

# Spatstat split into sub-packages
library(spatstat.geom)    # Spatial geometries
library(spatstat.explore) # Spatial exploration/KDE

# Set options
options(scipen = 999)  # No scientific notation
set.seed(5080)         # Reproducibility

# Create consistent theme for visualizations
theme_crime <- function(base_size = 11) {
  theme_minimal(base_size = base_size) +
    theme(
      plot.title = element_text(face = "bold", size = base_size + 1),
      plot.subtitle = element_text(color = "gray30", size = base_size - 1),
      legend.position = "right",
      panel.grid.minor = element_blank(),
      axis.text = element_blank(),
      axis.title = element_blank()
    )
}

# Set as default
theme_set(theme_crime())

cat("✓ All packages loaded successfully!\n")
cat("✓ Working directory:", getwd(), "\n")
```

# Part 1: Data Loading & Exploration

## 1.1: Load Chicago Spatial Data

```{r load-boundaries}
#| message: false

# Load police districts (used for spatial cross-validation)
policeDistricts <- 
  st_read("https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = dist_num)

# Load police beats (smaller administrative units)
policeBeats <- 
  st_read("https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(Beat = beat_num)

# Load Chicago boundary
chicagoBoundary <- 
  st_read("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson") %>%
  st_transform('ESRI:102271')

cat("✓ Loaded spatial boundaries\n")
cat("  - Police districts:", nrow(policeDistricts), "\n")
cat("  - Police beats:", nrow(policeBeats), "\n")
```

## 1.2: Load Alley Lights Out Calls

### This dataset contains all open 311 reports of one or more lights out on a wooden pole in the alley and all completed requests between 2011 and 2017. I chose this violation type because areas with dark alleys could be a sign that the area has been neglected and could therefore be a likely spot for crime.

```{r load-alley-lights-out}
#| message: false

alley_lightsout <- read_csv(here("labs/lab4/data/alley_lightsout.csv"))%>%
  filter(!is.na(Latitude), !is.na(Longitude)) %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
  st_transform('ESRI:102271')

cat("✓ Loaded alley lights out calls\n")
cat("  - Number of calls:", nrow(alley_lightsout), "\n")
```

## 1.3: Visualize Point Data

```{r visualize-points}
#| fig-width: 10
#| fig-height: 5

# Simple point map
p1 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_sf(data = alley_lightsout, color = "#d62828", size = 0.1, alpha = 0.4) +
  labs(
    title = "Dark Alley Locations",
    subtitle = paste0("Chicago 2011-2017, n = ", nrow(alley_lightsout))
  )

# Density surface using modern syntax
p2 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_density_2d_filled(
    data = data.frame(st_coordinates(alley_lightsout)),
    aes(X, Y),
    alpha = 0.7,
    bins = 8
  ) +
  scale_fill_viridis_d(
    option = "plasma",
    direction = -1,
    guide = "none"  # Modern ggplot2 syntax (not guide = FALSE)
  ) +
  labs(
    title = "Density Surface",
    subtitle = "Kernel density estimation"
  )

# Combine plots using patchwork (modern approach)
p1 + p2 + 
  plot_annotation(
    title = "Spatial Distribution of Dark Alleys in Chicago",
    tag_levels = 'A'
  )
```

### Alleys with lights out are found across Chicago, although they are far less common near the city center and in the far south. Looking at the density map there are concentrations in the nortwest and the south.

# Part 2: Fishnet Grid Creation

## 2.1: Create Fishnet

```{r create-fishnet}
# Create 500m x 500m grid
fishnet <- st_make_grid(
  chicagoBoundary,
  cellsize = 500,  # 500 meters per cell
  square = TRUE
) %>%
  st_sf() %>%
  mutate(uniqueID = row_number())

# Keep only cells that intersect Chicago
fishnet <- fishnet[chicagoBoundary, ]

# View basic info
cat("✓ Created fishnet grid\n")
cat("  - Number of cells:", nrow(fishnet), "\n")
cat("  - Cell size:", 500, "x", 500, "meters\n")
cat("  - Cell area:", round(st_area(fishnet[1,])), "square meters\n")
```

## 2.2 Aggregate Dark Alleys to Grid

```{r aggregate-dark-alleys}
# Spatial join: which cell contains each alley?
alley_fishnet <- st_join(alley_lightsout, fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(countDarkalleys = n())

# Join back to fishnet (cells with 0 dark alleys will be NA)
fishnet <- fishnet %>%
  left_join(alley_fishnet, by = "uniqueID" ) %>%
  mutate(countDarkalleys = replace_na(countDarkalleys, 0))

# Summary statistics
cat("\nDarkalley count distribution:\n")
summary(fishnet$countDarkalleys)
cat("\nCells with zero dark alleys:", 
    sum(fishnet$countDarkalleys == 0), 
    "/", nrow(fishnet),
    "(", round(100 * sum(fishnet$countDarkalleys == 0) / nrow(fishnet), 1), "%)\n")
```

## 2.3 Visualize Fishnet

```{r visualize-fishnet}
#| fig-width: 8
#| fig-height: 6

# Visualize aggregated counts
ggplot() +
  geom_sf(data = fishnet, aes(fill = countDarkalleys), color = NA) +
  geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
  scale_fill_viridis_c(
    name = "Dark Alleys",
    option = "plasma",
    trans = "sqrt",  # Square root for better visualization of skewed data
    breaks = c(0, 25, 500, 100, 200, 300, 400, 500, 600)
  ) +
  labs(
    title = "Alleys with Lights Out Counts by Grid Cell",
    subtitle = "500m x 500m cells, Chicago 2011-2017"
  ) +
  theme_crime()
```

### In this step I created a 500m x 500m fishnet grid, attached the Alleys with Lights Out points data to it and created a visualization of that distribution. A fishnet is useful here because it provides a consistent size for comparison and spatial analysis, whereas census tracts or other political boundaries vary in size. The visual reveals that the southern part of the city has a very low count. The cells with vary high counts seem to radiate out from the downtown area.

# Part 3: Spatial Features

## 3.1: Nearest Neighbor Features

### This step uses a nearest neighbors calculation to determine each cell's distance to the three nearest alleys with their lights out. This calculation takes in more of the local context compared to just measuring how many dark alleys are within a cell. The average distance to the 3 nearest dark alleys is 170 meters. Cells far away from dark alleys may be expected to have lower burglary counts.

```{r nn-feature}
#| message: false

# Calculate mean distance to 3 nearest dark alleys
# (Do this OUTSIDE of mutate to avoid sf conflicts)

# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(fishnet))
alley_coords <- st_coordinates(alley_lightsout)

# Calculate k nearest neighbors and distances
nn_result <- get.knnx(alley_coords, fishnet_coords, k = 3)

# Add to fishnet
fishnet <- fishnet %>%
  mutate(
    dark_alleys.nn = rowMeans(nn_result$nn.dist)
  )

cat("✓ Calculated nearest neighbor distances\n")
summary(fishnet$dark_alleys.nn)
```

## 3.2: Distance to Hot Spots

### Let's identify clusters of dark alleys using Local Moran's I, then calculate distance to these hot spots.

### Local Moran's I creates one value for each location and shows spatial autocorrelation, meaning in which spots is there clustering occurring. In this example, it shows where there are higher clusters of alleys with their lights out.This step is important because it provides a nuanced factor that could help predict where burglaries occur.

### Here we are using hotspots of dark alleys as a proxy of *"disorder"* but we must acknowledge that it is a flawed proxy.

```{r local-morans-alleys}
# Function to calculate Local Moran's I
calculate_local_morans <- function(data, variable, k = 5) {
  
  # Create spatial weights
  coords <- st_coordinates(st_centroid(data))
  neighbors <- knn2nb(knearneigh(coords, k = k))
  weights <- nb2listw(neighbors, style = "W", zero.policy = TRUE)
  
  # Calculate Local Moran's I
  local_moran <- localmoran(data[[variable]], weights)
  
  # Classify clusters
  mean_val <- mean(data[[variable]], na.rm = TRUE)
  
  data %>%
    mutate(
      local_i = local_moran[, 1],
      p_value = local_moran[, 5],
      is_significant = p_value < 0.05,
      
      moran_class = case_when(
        !is_significant ~ "Not Significant",
        local_i > 0 & .data[[variable]] > mean_val ~ "High-High",
        local_i > 0 & .data[[variable]] <= mean_val ~ "Low-Low",
        local_i < 0 & .data[[variable]] > mean_val ~ "High-Low",
        local_i < 0 & .data[[variable]] <= mean_val ~ "Low-High",
        TRUE ~ "Not Significant"
      )
    )
}

# Apply to dark alleys
fishnet <- calculate_local_morans(fishnet, "countDarkalleys", k = 5)
```

### This visualization shows that there is indeed clustering occurring. High-high areas are hotspots, meaning lots of dark alleys surrounded by more dark alleys. Low-low areas are coldspots - no dark alleys in this region. Low-high means an outlier area with a low count of dark alleys surrounded by an area with a high count of dark alleys. High-low means an outlier area with a high count of dark alleys surrounded by an area with a low count of dark alleys. There are small hotspots in the northwest and larger hotspots in the southwest and south. There are signifigant coldspots at the city center and the far south.

```{r visualize-morans}
#| fig-width: 8
#| fig-height: 6

# Visualize hot spots
ggplot() +
  geom_sf(
    data = fishnet, 
    aes(fill = moran_class), 
    color = NA
  ) +
  scale_fill_manual(
    values = c(
      "High-High" = "#d7191c",
      "High-Low" = "#fdae61",
      "Low-High" = "#abd9e9",
      "Low-Low" = "#2c7bb6",
      "Not Significant" = "gray90"
    ),
    name = "Cluster Type"
  ) +
  labs(
    title = "Local Moran's I: Alleys with Lights Out Clusters",
    subtitle = "High-High = Hot spots of disorder"
  ) +
  theme_crime()
```

### In this step below I measure each cell's distance to the nearest hot-spot. Cells closer to hot-spots have a higher proximity to disorder and may have higher burglary counts.

```{r distance-to-hotspots}
# Get centroids of "High-High" cells (hot spots)
hotspots <- fishnet %>%
  filter(moran_class == "High-High") %>%
  st_centroid()

# Calculate distance from each cell to nearest hot spot
if (nrow(hotspots) > 0) {
  fishnet <- fishnet %>%
    mutate(
      dist_to_hotspot = as.numeric(
        st_distance(st_centroid(fishnet), hotspots %>% st_union())
      )
    )
  
  cat("✓ Calculated distance to dark alley hot spots\n")
  cat("  - Number of hot spot cells:", nrow(hotspots), "\n")
} else {
  fishnet <- fishnet %>%
    mutate(dist_to_hotspot = 0)
  cat("⚠ No significant hot spots found\n")
}
```

# Part 4: Count Regression Models

## 4.1: Load Burglary Data

```{r load-burglaries}
#| message: false

# Load from provided data file (downloaded from Chicago open data portal)
burglaries <- st_read(here("C:/Users/annal/OneDrive/Documents/Weitzman/MUSA-5080-Fall-2025/lectures/week-09/data/burglaries.shp")) %>% 
  st_transform('ESRI:102271')

# Check the data
cat("\n✓ Loaded burglary data\n")
cat("  - Number of burglaries:", nrow(burglaries), "\n")
cat("  - CRS:", st_crs(burglaries)$input, "\n")
cat("  - Date range:", min(burglaries$date, na.rm = TRUE), "to", 
    max(burglaries$date, na.rm = TRUE), "\n")
```

## 4.2: Aggregate Burglaries to Grid

```{r aggregate-burglaries}
# Spatial join: which cell contains each burglary?
burglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(countBurglaries = n())

# Join back to fishnet (cells with 0 burglaries will be NA)
fishnet <- fishnet %>%
  left_join(burglaries_fishnet, by = "uniqueID") %>%
  mutate(countBurglaries = replace_na(countBurglaries, 0))

# Summary statistics
cat("\nBurglary count distribution:\n")
summary(fishnet$countBurglaries)
cat("\nCells with zero burglaries:", 
    sum(fishnet$countBurglaries == 0), 
    "/", nrow(fishnet),
    "(", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), "%)\n")
```

## 4.3 : Join police districts

```{r join-districts}
# Join district information to fishnet
fishnet <- st_join(
  fishnet,
  policeDistricts,
  join = st_within,
  left = TRUE
) %>%
  filter(!is.na(District))  # Remove cells outside districts

cat("✓ Joined police districts\n")
cat("  - Districts:", length(unique(fishnet$District)), "\n")
cat("  - Cells:", nrow(fishnet), "\n")
```

## 4.4: Poisson Regression

### We use poisson regression rather than linear regression because linear regression can predict negative values, which is impossible when predicting the number of burglaries. It also has other problems, such as assuming continuous outcomes, whereas burglary counts are discrete.

```{r prepare-data}
# Create clean modeling dataset
fishnet_model <- fishnet %>%
  st_drop_geometry() %>%
  dplyr::select(
    uniqueID,
    District,
    countBurglaries,
    countDarkalleys,
    dark_alleys.nn,
    dist_to_hotspot
  ) %>%
  na.omit()  # Remove any remaining NAs

cat("✓ Prepared modeling data\n")
cat("  - Observations:", nrow(fishnet_model), "\n")
cat("  - Variables:", ncol(fishnet_model), "\n")
```

```{r fit-poisson}
# Fit Poisson regression
model_poisson <- glm(
  countBurglaries ~ countDarkalleys + dark_alleys.nn + 
    dist_to_hotspot,
  data = fishnet_model,
  family = "poisson"
)

# Summary
summary(model_poisson)
```

### When these coefficients are exponentiated, this model predicts that there are 0.16% more burglaries per extra dark alley inside the grid cell, there are −0.62% fewer burglaries per additional dark alley nearby, and a \~0.0055% decrease per meter away from the nearest dark alley hot-spot. All 3 variables are signifigant. The dispersion calculation is about 1 which means there is not strong overdispersion.

### Overall, burglary risk increases where dark alleys exist within a grid cell, but decreases when dark alleys are more prevalent in neighboring cells. Risk also declines with distance from known burglary hotspots.

## 4.4: Negative Binomial Regression

### If overdispersed, use **Negative Binomial regression** (more flexible).

### Negative Binomial Regression can be a better model option when there is overdispersion. It adds a dispersion parameter.

```{r fit-negbin}
# Fit Negative Binomial model
model_nb <- glm.nb(
  countBurglaries ~ countDarkalleys + dark_alleys.nn + 
    dist_to_hotspot,
  data = fishnet_model
)

# Summary
summary(model_nb)

# Compare AIC (lower is better)
cat("\nModel Comparison:\n")
cat("Poisson AIC:", round(AIC(model_poisson), 1), "\n")
cat("Negative Binomial AIC:", round(AIC(model_nb), 1), "\n")
```

### When the coefficients are exponentiated, the model predicts +0.175% burglaries per added dark alley inside the cell, −0.68% burglaries per additional meter away from the 3 nearest dark alleys, and a .004% decrease in burglaries per additional meter away from the nearest hot-spot.

### With an AIC of 7418 compared to the Poisson model's AIC of 8809, the negative binomial model is clearly preferred.

# Part 5: Spatial Cross-Validation (2017)

### **Leave-One-Group-Out (LOGO) Cross-Validation** trains on all districts except one, then tests on the held-out district.

### Standard cross-validation does not work for spatial data, so we have to use spatial cross-validation. The LOGO-CV approach leaves out entire spatial group instead of individual cells for training, and then tests them later. In this case we used police districts for the groupings.

```{r spatial-cv}
# Get unique districts
districts <- unique(fishnet_model$District)
cv_results <- tibble()

cat("Running LOGO Cross-Validation...\n")

for (i in seq_along(districts)) {
  
  test_district <- districts[i]
  
  # Split data
  train_data <- fishnet_model %>% filter(District != test_district)
  test_data <- fishnet_model %>% filter(District == test_district)
  
  # Fit model on training data
  model_cv <- glm.nb(
    countBurglaries ~ countDarkalleys + dark_alleys.nn + 
      dist_to_hotspot,
    data = train_data
  )
  
  # Predict on test data
  test_data <- test_data %>%
    mutate(
      prediction = predict(model_cv, test_data, type = "response")
    )
  
  # Calculate metrics
  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))
  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))
  
  # Store results
  cv_results <- bind_rows(
    cv_results,
    tibble(
      fold = i,
      test_district = test_district,
      n_test = nrow(test_data),
      mae = mae,
      rmse = rmse
    )
  )
  
  cat("  Fold", i, "/", length(districts), "- District", test_district, 
      "- MAE:", round(mae, 2), "\n")
}

# Overall results
cat("\n✓ Cross-Validation Complete\n")
cat("Mean MAE:", round(mean(cv_results$mae), 2), "\n")
cat("Mean RMSE:", round(mean(cv_results$rmse), 2), "\n")
```

### The cross validation shows that on average the model is off by about 2.5 burglaries per cell (MAE). It struggles in hot-spot areas since the mean RMSE is higher at 3.44.

```{r cv-results-table}
# Show results
cv_results %>%
  arrange(desc(mae)) %>%
  kable(
    digits = 2,
    caption = "LOGO CV Results by District"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Part 6: Model Evaluation

## 6.1: Create a Kernel Density Baseline to compare our model to.

## **The KDE baseline asks:** "What if crime just happens where it happened before?" (simple spatial smoothing, no predictors)

```{r kde-baseline}
#| message: false

# Convert burglaries to ppp (point pattern) format for spatstat
burglaries_ppp <- as.ppp(
  st_coordinates(burglaries),
  W = as.owin(st_bbox(chicagoBoundary))
)

# Calculate KDE with 1km bandwidth
kde_burglaries <- density.ppp(
  burglaries_ppp,
  sigma = 1000,  # 1km bandwidth
  edge = TRUE    # Edge correction
)

# Convert to terra raster (modern approach, not raster::raster)
kde_raster <- rast(kde_burglaries)

# Extract KDE values to fishnet cells
fishnet <- fishnet %>%
  mutate(
    kde_value = terra::extract(
      kde_raster,
      vect(fishnet),
      fun = mean,
      na.rm = TRUE
    )[, 2]  # Extract just the values column
  )

cat("✓ Calculated KDE baseline\n")
```

```{r visualize-kde}
#| fig-width: 8
#| fig-height: 6

ggplot() +
  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +
  geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
  scale_fill_viridis_c(
    name = "KDE Value",
    option = "plasma"
  ) +
  labs(
    title = "Kernel Density Estimation Baseline",
    subtitle = "Simple spatial smoothing of burglary locations"
  ) +
  theme_crime()
```

## 6.2: Generate Final Predictions

```{r final-predictions}
# Fit final model on all data
final_model <- glm.nb(
  countBurglaries ~ countDarkalleys + dark_alleys.nn + 
    dist_to_hotspot,
  data = fishnet_model
)

# Add predictions back to fishnet
fishnet <- fishnet %>%
  mutate(
    prediction_nb = predict(final_model, fishnet_model, type = "response")[match(uniqueID, fishnet_model$uniqueID)]
  )

# Also add KDE predictions (normalize to same scale as counts)
kde_sum <- sum(fishnet$kde_value, na.rm = TRUE)
count_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)
fishnet <- fishnet %>%
  mutate(
    prediction_kde = (kde_value / kde_sum) * count_sum
  )
```

## 6.3: Compare Model vs. KDE Baseline

```{r compare-models}
#| fig-width: 12
#| fig-height: 4

# Create three maps
p1 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
  scale_fill_viridis_c(name = "Count", option = "plasma", limits = c(0, 15)) +
  labs(title = "Actual Burglaries") +
  theme_crime()

p2 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +
  scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
  labs(title = "Model Predictions (Neg. Binomial)") +
  theme_crime()

p3 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +
  scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
  labs(title = "KDE Baseline Predictions") +
  theme_crime()

p1 + p2 + p3 +
  plot_annotation(
    title = "Actual vs. Predicted Burglaries",
    subtitle = "Does our complex model outperform simple KDE?"
  )
```

```{r model-comparison-metrics}
# Calculate performance metrics
comparison <- fishnet %>%
  st_drop_geometry() %>%
  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%
  summarize(
    model_mae = mean(abs(countBurglaries - prediction_nb)),
    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),
    kde_mae = mean(abs(countBurglaries - prediction_kde)),
    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))
  )

comparison %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  separate(metric, into = c("approach", "metric"), sep = "_") %>%
  pivot_wider(names_from = metric, values_from = value) %>%
  kable(
    digits = 2,
    caption = "Model Performance Comparison"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

### Based on the above results the Kernel Density Model performs better than the model in terms of both MAE and RMSE. The KDE model is purely spatial and does not take into account predictors of burglaries. The negative binomial model shows the relationship between proximity to dark alleys and burglaries, but does not capture the spatial geometry of burglaries as well.

## 6.4: Where Does the Model Work Well? Where are the largest errors?

```{r prediction-errors}
#| fig-width: 10
#| fig-height: 5

# Calculate errors
fishnet <- fishnet %>%
  mutate(
    error_nb = countBurglaries - prediction_nb,
    error_kde = countBurglaries - prediction_kde,
    abs_error_nb = abs(error_nb),
    abs_error_kde = abs(error_kde)
  )

# Map errors
p1 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +
  scale_fill_gradient2(
    name = "Error",
    low = "#2166ac", mid = "white", high = "#b2182b",
    midpoint = 0,
    limits = c(-10, 10)
  ) +
  labs(title = "Model Errors (Actual - Predicted)") +
  theme_crime()

p2 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +
  scale_fill_viridis_c(name = "Abs. Error", option = "magma") +
  labs(title = "Absolute Model Errors") +
  theme_crime()

p1 + p2
```

### This step maps the negative binomial model's errors. This is useful to see if their are spatial patterns in the errors. The graphic shows that the model overpredicted burglaries in certain northern and southern areas. It underpredicted burglaries especially in the northern and eastern boundaries of the city.

## 6.5 Model Summary Table

```{r model-summary-table}
# Create nice summary table
model_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%
  mutate(
    across(where(is.numeric), ~round(., 3))
  )

model_summary %>%
  kable(
    caption = "Final Negative Binomial Model Coefficients (Exponentiated)",
    col.names = c("Variable", "Rate Ratio", "Std. Error", "Z", "P-Value")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  footnote(
    general = "Rate ratios > 1 indicate positive association with burglary counts."
  )
```
