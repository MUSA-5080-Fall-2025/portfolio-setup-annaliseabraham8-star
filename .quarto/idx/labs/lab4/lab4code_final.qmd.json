{"title":"Lab Assignment 4: Spatial Predictive Analysis","markdown":{"yaml":{"title":"Lab Assignment 4: Spatial Predictive Analysis","subtitle":"MUSA 5080 - Fall 2025","author":"Annalise Abraham","date":"today","format":{"html":{"code-fold":"show","code-tools":true,"toc":true,"toc-depth":3,"toc-location":"left","theme":"cosmo","embed-resources":true}},"editor":"visual","execute":{"warning":false,"message":false}},"headingText":"Table of Contents","containsRefs":false,"markdown":"\n\n\n## *Introduction*\n\n## *Part 1: Data Loading and Exploration*\n\n## *Part 2: Fishnet Grid Creation*\n\n## *Part 3: Spatial Features*\n\n## *Part 4: Count Regression Models*\n\n## *Part 5: Spatial Cross Validation*\n\n## *Part 6: Model Evaluation*\n\n# Introduction\n\n## Assignment Overview\n\nIn this lab, you will apply the spatial predictive modeling techniques demonstrated in the class exercise using a different 311 service request type of your choice as the predictor variable. You will build a complete spatial predictive model, document your process, and interpret your results.\n\n### Timeline & Deliverables\n\n**Due Date:** November 17, 2025, 10:00AM\n\n**Deliverable:** One rendered document, posted to your portfolio website.\n\n### Learning Goals\n\nBy completing this assignment, you will demonstrate your ability to:\n\n-   Adapt example code to analyze a new dataset\n-   Build spatial features for predictive modeling\n-   Apply count regression techniques to spatial data\n-   Implement spatial cross-validation\n-   Interpret and communicate model results\n-   Critically evaluate model performance\n\n## Setup\n\n```{r setup}\n#| message: false\n#| warning: false\n\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\ncat(\"✓ Working directory:\", getwd(), \"\\n\")\n```\n\n## Step 1: Choose Your 311 Violation Type\n\n### Getting the Data\n\nVisit the Chicago 311 Service Requests dataset:\n\n**https://data.cityofchicago.org/stories/s/311-Dataset-Changes-12-11-2018/d7nq-5g7t**\n\nBrowse the available service request types (e.g., Graffiti Removal, Pothole Repair, Street Light Out, Sanitation Code Violations, etc.) and **choose one violation type** that interests you.\n\n### Requirements for Your Choice\n\n-   Choose a **different** violation type than the abandoned cars we did in class.\n\n## Step 2: Complete the Analysis\n\nUsing the class exercise as your template, adapt the code to analyze your chosen 311 violation type.\n\n### What to Include\n\nWork through all major sections of the analysis:\n\n# Part 1: Data Loading & Exploration\n\n-   Load your 311 data and Chicago spatial boundaries\n-   Create visualizations showing the spatial distribution of your violation type\n-   Describe patterns you observe\n\n## 1.1: Load Chicago Spatial Data\n\n```{r load-boundaries}\n#| message: false\n\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\") %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded spatial boundaries\\n\")\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n## 1.2: Load Alley Lights Out Calls\n\nThis dataset contains all open 311 reports of one or more lights out on a wooden pole in the alley and all completed requests between 2011 and 2017. I chose this violation type because areas with dark alleys could be a sign that the area has been neglected and could therefore be a likely spot for crime.\n\n```{r load-alley-lights-out}\n#| message: false\n\nalley_lightsout <- read_csv(here(\"labs/lab4/data/alley_lightsout.csv\"))%>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded alley lights out calls\\n\")\ncat(\"  - Number of calls:\", nrow(alley_lightsout), \"\\n\")\n```\n\n## 1.3: Visualize Point Data\n\n```{r visualize-points}\n#| fig-width: 10\n#| fig-height: 5\n\n# Simple point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = alley_lightsout, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Dark Alley Locations\",\n    subtitle = paste0(\"Chicago 2011-2017, n = \", nrow(alley_lightsout))\n  )\n\n# Density surface using modern syntax\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(alley_lightsout)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"  # Modern ggplot2 syntax (not guide = FALSE)\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Combine plots using patchwork (modern approach)\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Dark Alleys in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n### Alleys with lights out are found across Chicago, although they are far less common near the city center and in the far south. Looking at the density map there are concentrations in the nortwest and the south.\n\n# Part 2: Fishnet Grid Creation\n\n-   Create a 500m x 500m fishnet grid\n-   Aggregate your violations to grid cells\n-   Visualize the count distribution\n\n## 2.1: Create Fishnet\n\n```{r create-fishnet}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n## 2.2 Aggregate Dark Alleys to Grid\n\n```{r aggregate-dark-alleys}\n# Spatial join: which cell contains each alley?\nalley_fishnet <- st_join(alley_lightsout, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countDarkalleys = n())\n\n# Join back to fishnet (cells with 0 dark alleys will be NA)\nfishnet <- fishnet %>%\n  left_join(alley_fishnet, by = \"uniqueID\" ) %>%\n  mutate(countDarkalleys = replace_na(countDarkalleys, 0))\n\n# Summary statistics\ncat(\"\\nDarkalley count distribution:\\n\")\nsummary(fishnet$countDarkalleys)\ncat(\"\\nCells with zero dark alleys:\", \n    sum(fishnet$countDarkalleys == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countDarkalleys == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n## 2.3 Visualize Fishnet\n\n```{r visualize-fishnet}\n#| fig-width: 8\n#| fig-height: 6\n\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countDarkalleys), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Dark Alleys\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 25, 500, 100, 200, 300, 400, 500, 600)\n  ) +\n  labs(\n    title = \"Alleys with Lights Out Counts by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2011-2017\"\n  ) +\n  theme_crime()\n```\n\n### In this step I created a 500m x 500m fishnet grid, attached the Alleys with Lights Out points data to it and created a visualization of that distribution. A fishnet is useful here because it provides a consistent size for comparison and spatial analysis, whereas census tracts or other political boundaries vary in size. The visual reveals that the southern part of the city has a very low count. The cells with vary high counts seem to radiate out from the downtown area.\n\n# Part 3: Spatial Features\n\n-   Calculate k-nearest neighbor features\n-   Perform Local Moran's I analysis\n-   Identify hot spots and cold spots\n-   Create distance-to-hotspot measures\n-   Join any additional contextual data if you are looking for more to do and really get into this (e.g., demographics, land use)\n\n## 3.1: Nearest Neighbor Features\n\n### This step uses a nearest neighbors calculation to determine each cell's distance to the three nearest alleys with their lights out. This calculation takes in more of the local context compared to just measuring how many dark alleys are within a cell. The average distance to the 3 nearest dark alleys is 170 meters. Cells far away from dark alleys may be expected to have lower burglary counts.\n\n```{r nn-feature}\n#| message: false\n\n# Calculate mean distance to 3 nearest dark alleys\n# (Do this OUTSIDE of mutate to avoid sf conflicts)\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nalley_coords <- st_coordinates(alley_lightsout)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(alley_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    dark_alleys.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\nsummary(fishnet$dark_alleys.nn)\n```\n\n## 3.2: Distance to Hot Spots\n\n### Let's identify clusters of dark alleys using Local Moran's I, then calculate distance to these hot spots.\n\n### Local Moran's I creates one value for each location and shows spatial autocorrelation, meaning in which spots is there clustering occurring. In this example, it shows where there are higher clusters of alleys with their lights out.This step is important because it provides a nuanced factor that could help predict where burglaries occur.\n\n### Here we are using hotspots of dark alleys as a proxy of *\"disorder\"* but we must acknowledge that it is a flawed proxy.\n\n```{r local-morans-alleys}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      \n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\n# Apply to dark alleys\nfishnet <- calculate_local_morans(fishnet, \"countDarkalleys\", k = 5)\n```\n\n### This visualization shows that there is indeed clustering occurring. High-high areas are hotspots, meaning lots of dark alleys surrounded by more dark alleys. Low-low areas are coldspots - no dark alleys in this region. Low-high means an outlier area with a low count of dark alleys surrounded by an area with a high count of dark alleys. High-low means an outlier area with a high count of dark alleys surrounded by an area with a low count of dark alleys. There are small hotspots in the northwest and larger hotspots in the southwest and south. There are signifigant coldspots at the city center and the far south.\n\n```{r visualize-morans}\n#| fig-width: 8\n#| fig-height: 6\n\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Alleys with Lights Out Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n### In this step below I measure each cell's distance to the nearest hot-spot. Cells closer to hot-spots have a higher proximity to disorder and may have higher burglary counts.\n\n```{r distance-to-hotspots}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to dark alley hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n# Part 4: Count Regression Models\n\n-   Fit Poisson regression\n-   Fit Negative Binomial regression\n-   Compare model fit (AIC)\n\n## 4.1: Load Burglary Data\n\n```{r load-burglaries}\n#| message: false\n\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"C:/Users/annal/OneDrive/Documents/Weitzman/MUSA-5080-Fall-2025/lectures/week-09/data/burglaries.shp\")) %>% \n  st_transform('ESRI:102271')\n\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\ncat(\"  - CRS:\", st_crs(burglaries)$input, \"\\n\")\ncat(\"  - Date range:\", min(burglaries$date, na.rm = TRUE), \"to\", \n    max(burglaries$date, na.rm = TRUE), \"\\n\")\n```\n\n## 4.2: Aggregate Burglaries to Grid\n\n```{r aggregate-burglaries}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\nsummary(fishnet$countBurglaries)\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n## 4.3 : Join police districts\n\n```{r join-districts}\n# Join district information to fishnet\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n## 4.4: Poisson Regression\n\n### We use poisson regression rather than linear regression because linear regression can predict negative values, which is impossible when predicting the number of burglaries. It also has other problems, such as assuming continuous outcomes, whereas burglary counts are discrete.\n\n```{r prepare-data}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    countDarkalleys,\n    dark_alleys.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n```{r fit-poisson}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ countDarkalleys + dark_alleys.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n### When these coefficients are exponentiated, this model predicts that there are 0.16% more burglaries per extra dark alley inside the grid cell, there are −0.62% fewer burglaries per additional dark alley nearby, and a \\~0.0055% decrease per meter away from the nearest dark alley hot-spot. All 3 variables are signifigant. The dispersion calculation is about 1 which means there is not strong overdispersion.\n\n### Overall, burglary risk increases where dark alleys exist within a grid cell, but decreases when dark alleys are more prevalent in neighboring cells. Risk also declines with distance from known burglary hotspots.\n\n## 4.4: Negative Binomial Regression\n\n### If overdispersed, use **Negative Binomial regression** (more flexible).\n\n### Negative Binomial Regression can be a better model option when there is overdispersion. It adds a dispersion parameter.\n\n```{r fit-negbin}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ countDarkalleys + dark_alleys.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n### When the coefficients are exponentiated, the model predicts +0.175% burglaries per added dark alley inside the cell, −0.68% burglaries per additional meter away from the 3 nearest dark alleys, and a .004% decrease in burglaries per additional meter away from the nearest hot-spot.\n\n### With an AIC of 7418 compared to the Poisson model's AIC of 8809, the negative binomial model is clearly preferred.\n\n# Part 5: Spatial Cross-Validation (2017)\n\n-   Implement Leave-One-Group-Out cross-validation on 2017 data\n-   Calculate and report error metrics (MAE, RMSE)\n\n### **Leave-One-Group-Out (LOGO) Cross-Validation** trains on all districts except one, then tests on the held-out district.\n\n### Standard cross-validation does not work for spatial data, so we have to use spatial cross-validation. The LOGO-CV approach leaves out entire spatial group instead of individual cells for training, and then tests them later. In this case we used police districts for the groupings.\n\n```{r spatial-cv}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ countDarkalleys + dark_alleys.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n### The cross validation shows that on average the model is off by about 2.5 burglaries per cell (MAE). It struggles in hot-spot areas since the mean RMSE is higher at 3.44.\n\n```{r cv-results-table}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n# Part 6: Model Evaluation\n\n-   Compare to KDE baseline\n\n## 6.1: Create a Kernel Density Baseline to compare our model to.\n\n## **The KDE baseline asks:** \"What if crime just happens where it happened before?\" (simple spatial smoothing, no predictors)\n\n```{r kde-baseline}\n#| message: false\n\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n```{r visualize-kde}\n#| fig-width: 8\n#| fig-height: 6\n\nggplot() +\n  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"KDE Value\",\n    option = \"plasma\"\n  ) +\n  labs(\n    title = \"Kernel Density Estimation Baseline\",\n    subtitle = \"Simple spatial smoothing of burglary locations\"\n  ) +\n  theme_crime()\n```\n\n## 6.2: Generate Final Predictions\n\n```{r final-predictions}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ countDarkalleys + dark_alleys.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n\n## 6.3: Compare Model vs. KDE Baseline\n\n```{r compare-models}\n#| fig-width: 12\n#| fig-height: 4\n\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n```{r model-comparison-metrics}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n### Based on the above results the Kernel Density Model performs better than the model in terms of both MAE and RMSE. The KDE model is purely spatial and does not take into account predictors of burglaries. The negative binomial model shows the relationship between proximity to dark alleys and burglaries, but does not capture the spatial geometry of burglaries as well.\n\n## 6.4: Where Does the Model Work Well? Where are the largest errors?\n\n```{r prediction-errors}\n#| fig-width: 10\n#| fig-height: 5\n\n# Calculate errors\nfishnet <- fishnet %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"magma\") +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2\n```\n\n### This step maps the negative binomial model's errors. This is useful to see if their are spatial patterns in the errors. The graphic shows that the model overpredicted burglaries in certain northern and southern areas. It underpredicted burglaries especially in the northern and eastern boundaries of the city.\n\n## 6.5 Model Summary Table\n\n```{r model-summary-table}\n# Create nice summary table\nmodel_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%\n  mutate(\n    across(where(is.numeric), ~round(., 3))\n  )\n\nmodel_summary %>%\n  kable(\n    caption = \"Final Negative Binomial Model Coefficients (Exponentiated)\",\n    col.names = c(\"Variable\", \"Rate Ratio\", \"Std. Error\", \"Z\", \"P-Value\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  footnote(\n    general = \"Rate ratios > 1 indicate positive association with burglary counts.\"\n  )\n```\n","srcMarkdownNoYaml":"\n\n# Table of Contents\n\n## *Introduction*\n\n## *Part 1: Data Loading and Exploration*\n\n## *Part 2: Fishnet Grid Creation*\n\n## *Part 3: Spatial Features*\n\n## *Part 4: Count Regression Models*\n\n## *Part 5: Spatial Cross Validation*\n\n## *Part 6: Model Evaluation*\n\n# Introduction\n\n## Assignment Overview\n\nIn this lab, you will apply the spatial predictive modeling techniques demonstrated in the class exercise using a different 311 service request type of your choice as the predictor variable. You will build a complete spatial predictive model, document your process, and interpret your results.\n\n### Timeline & Deliverables\n\n**Due Date:** November 17, 2025, 10:00AM\n\n**Deliverable:** One rendered document, posted to your portfolio website.\n\n### Learning Goals\n\nBy completing this assignment, you will demonstrate your ability to:\n\n-   Adapt example code to analyze a new dataset\n-   Build spatial features for predictive modeling\n-   Apply count regression techniques to spatial data\n-   Implement spatial cross-validation\n-   Interpret and communicate model results\n-   Critically evaluate model performance\n\n## Setup\n\n```{r setup}\n#| message: false\n#| warning: false\n\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\ncat(\"✓ Working directory:\", getwd(), \"\\n\")\n```\n\n## Step 1: Choose Your 311 Violation Type\n\n### Getting the Data\n\nVisit the Chicago 311 Service Requests dataset:\n\n**https://data.cityofchicago.org/stories/s/311-Dataset-Changes-12-11-2018/d7nq-5g7t**\n\nBrowse the available service request types (e.g., Graffiti Removal, Pothole Repair, Street Light Out, Sanitation Code Violations, etc.) and **choose one violation type** that interests you.\n\n### Requirements for Your Choice\n\n-   Choose a **different** violation type than the abandoned cars we did in class.\n\n## Step 2: Complete the Analysis\n\nUsing the class exercise as your template, adapt the code to analyze your chosen 311 violation type.\n\n### What to Include\n\nWork through all major sections of the analysis:\n\n# Part 1: Data Loading & Exploration\n\n-   Load your 311 data and Chicago spatial boundaries\n-   Create visualizations showing the spatial distribution of your violation type\n-   Describe patterns you observe\n\n## 1.1: Load Chicago Spatial Data\n\n```{r load-boundaries}\n#| message: false\n\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\") %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded spatial boundaries\\n\")\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n## 1.2: Load Alley Lights Out Calls\n\nThis dataset contains all open 311 reports of one or more lights out on a wooden pole in the alley and all completed requests between 2011 and 2017. I chose this violation type because areas with dark alleys could be a sign that the area has been neglected and could therefore be a likely spot for crime.\n\n```{r load-alley-lights-out}\n#| message: false\n\nalley_lightsout <- read_csv(here(\"labs/lab4/data/alley_lightsout.csv\"))%>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded alley lights out calls\\n\")\ncat(\"  - Number of calls:\", nrow(alley_lightsout), \"\\n\")\n```\n\n## 1.3: Visualize Point Data\n\n```{r visualize-points}\n#| fig-width: 10\n#| fig-height: 5\n\n# Simple point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = alley_lightsout, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Dark Alley Locations\",\n    subtitle = paste0(\"Chicago 2011-2017, n = \", nrow(alley_lightsout))\n  )\n\n# Density surface using modern syntax\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(alley_lightsout)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"  # Modern ggplot2 syntax (not guide = FALSE)\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Combine plots using patchwork (modern approach)\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Dark Alleys in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n### Alleys with lights out are found across Chicago, although they are far less common near the city center and in the far south. Looking at the density map there are concentrations in the nortwest and the south.\n\n# Part 2: Fishnet Grid Creation\n\n-   Create a 500m x 500m fishnet grid\n-   Aggregate your violations to grid cells\n-   Visualize the count distribution\n\n## 2.1: Create Fishnet\n\n```{r create-fishnet}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n## 2.2 Aggregate Dark Alleys to Grid\n\n```{r aggregate-dark-alleys}\n# Spatial join: which cell contains each alley?\nalley_fishnet <- st_join(alley_lightsout, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countDarkalleys = n())\n\n# Join back to fishnet (cells with 0 dark alleys will be NA)\nfishnet <- fishnet %>%\n  left_join(alley_fishnet, by = \"uniqueID\" ) %>%\n  mutate(countDarkalleys = replace_na(countDarkalleys, 0))\n\n# Summary statistics\ncat(\"\\nDarkalley count distribution:\\n\")\nsummary(fishnet$countDarkalleys)\ncat(\"\\nCells with zero dark alleys:\", \n    sum(fishnet$countDarkalleys == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countDarkalleys == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n## 2.3 Visualize Fishnet\n\n```{r visualize-fishnet}\n#| fig-width: 8\n#| fig-height: 6\n\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countDarkalleys), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Dark Alleys\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 25, 500, 100, 200, 300, 400, 500, 600)\n  ) +\n  labs(\n    title = \"Alleys with Lights Out Counts by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2011-2017\"\n  ) +\n  theme_crime()\n```\n\n### In this step I created a 500m x 500m fishnet grid, attached the Alleys with Lights Out points data to it and created a visualization of that distribution. A fishnet is useful here because it provides a consistent size for comparison and spatial analysis, whereas census tracts or other political boundaries vary in size. The visual reveals that the southern part of the city has a very low count. The cells with vary high counts seem to radiate out from the downtown area.\n\n# Part 3: Spatial Features\n\n-   Calculate k-nearest neighbor features\n-   Perform Local Moran's I analysis\n-   Identify hot spots and cold spots\n-   Create distance-to-hotspot measures\n-   Join any additional contextual data if you are looking for more to do and really get into this (e.g., demographics, land use)\n\n## 3.1: Nearest Neighbor Features\n\n### This step uses a nearest neighbors calculation to determine each cell's distance to the three nearest alleys with their lights out. This calculation takes in more of the local context compared to just measuring how many dark alleys are within a cell. The average distance to the 3 nearest dark alleys is 170 meters. Cells far away from dark alleys may be expected to have lower burglary counts.\n\n```{r nn-feature}\n#| message: false\n\n# Calculate mean distance to 3 nearest dark alleys\n# (Do this OUTSIDE of mutate to avoid sf conflicts)\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nalley_coords <- st_coordinates(alley_lightsout)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(alley_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    dark_alleys.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\nsummary(fishnet$dark_alleys.nn)\n```\n\n## 3.2: Distance to Hot Spots\n\n### Let's identify clusters of dark alleys using Local Moran's I, then calculate distance to these hot spots.\n\n### Local Moran's I creates one value for each location and shows spatial autocorrelation, meaning in which spots is there clustering occurring. In this example, it shows where there are higher clusters of alleys with their lights out.This step is important because it provides a nuanced factor that could help predict where burglaries occur.\n\n### Here we are using hotspots of dark alleys as a proxy of *\"disorder\"* but we must acknowledge that it is a flawed proxy.\n\n```{r local-morans-alleys}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      \n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\n# Apply to dark alleys\nfishnet <- calculate_local_morans(fishnet, \"countDarkalleys\", k = 5)\n```\n\n### This visualization shows that there is indeed clustering occurring. High-high areas are hotspots, meaning lots of dark alleys surrounded by more dark alleys. Low-low areas are coldspots - no dark alleys in this region. Low-high means an outlier area with a low count of dark alleys surrounded by an area with a high count of dark alleys. High-low means an outlier area with a high count of dark alleys surrounded by an area with a low count of dark alleys. There are small hotspots in the northwest and larger hotspots in the southwest and south. There are signifigant coldspots at the city center and the far south.\n\n```{r visualize-morans}\n#| fig-width: 8\n#| fig-height: 6\n\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Alleys with Lights Out Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n### In this step below I measure each cell's distance to the nearest hot-spot. Cells closer to hot-spots have a higher proximity to disorder and may have higher burglary counts.\n\n```{r distance-to-hotspots}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to dark alley hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n# Part 4: Count Regression Models\n\n-   Fit Poisson regression\n-   Fit Negative Binomial regression\n-   Compare model fit (AIC)\n\n## 4.1: Load Burglary Data\n\n```{r load-burglaries}\n#| message: false\n\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"C:/Users/annal/OneDrive/Documents/Weitzman/MUSA-5080-Fall-2025/lectures/week-09/data/burglaries.shp\")) %>% \n  st_transform('ESRI:102271')\n\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\ncat(\"  - CRS:\", st_crs(burglaries)$input, \"\\n\")\ncat(\"  - Date range:\", min(burglaries$date, na.rm = TRUE), \"to\", \n    max(burglaries$date, na.rm = TRUE), \"\\n\")\n```\n\n## 4.2: Aggregate Burglaries to Grid\n\n```{r aggregate-burglaries}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\nsummary(fishnet$countBurglaries)\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n## 4.3 : Join police districts\n\n```{r join-districts}\n# Join district information to fishnet\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n## 4.4: Poisson Regression\n\n### We use poisson regression rather than linear regression because linear regression can predict negative values, which is impossible when predicting the number of burglaries. It also has other problems, such as assuming continuous outcomes, whereas burglary counts are discrete.\n\n```{r prepare-data}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    countDarkalleys,\n    dark_alleys.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n```{r fit-poisson}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ countDarkalleys + dark_alleys.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n### When these coefficients are exponentiated, this model predicts that there are 0.16% more burglaries per extra dark alley inside the grid cell, there are −0.62% fewer burglaries per additional dark alley nearby, and a \\~0.0055% decrease per meter away from the nearest dark alley hot-spot. All 3 variables are signifigant. The dispersion calculation is about 1 which means there is not strong overdispersion.\n\n### Overall, burglary risk increases where dark alleys exist within a grid cell, but decreases when dark alleys are more prevalent in neighboring cells. Risk also declines with distance from known burglary hotspots.\n\n## 4.4: Negative Binomial Regression\n\n### If overdispersed, use **Negative Binomial regression** (more flexible).\n\n### Negative Binomial Regression can be a better model option when there is overdispersion. It adds a dispersion parameter.\n\n```{r fit-negbin}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ countDarkalleys + dark_alleys.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n### When the coefficients are exponentiated, the model predicts +0.175% burglaries per added dark alley inside the cell, −0.68% burglaries per additional meter away from the 3 nearest dark alleys, and a .004% decrease in burglaries per additional meter away from the nearest hot-spot.\n\n### With an AIC of 7418 compared to the Poisson model's AIC of 8809, the negative binomial model is clearly preferred.\n\n# Part 5: Spatial Cross-Validation (2017)\n\n-   Implement Leave-One-Group-Out cross-validation on 2017 data\n-   Calculate and report error metrics (MAE, RMSE)\n\n### **Leave-One-Group-Out (LOGO) Cross-Validation** trains on all districts except one, then tests on the held-out district.\n\n### Standard cross-validation does not work for spatial data, so we have to use spatial cross-validation. The LOGO-CV approach leaves out entire spatial group instead of individual cells for training, and then tests them later. In this case we used police districts for the groupings.\n\n```{r spatial-cv}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ countDarkalleys + dark_alleys.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n### The cross validation shows that on average the model is off by about 2.5 burglaries per cell (MAE). It struggles in hot-spot areas since the mean RMSE is higher at 3.44.\n\n```{r cv-results-table}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n# Part 6: Model Evaluation\n\n-   Compare to KDE baseline\n\n## 6.1: Create a Kernel Density Baseline to compare our model to.\n\n## **The KDE baseline asks:** \"What if crime just happens where it happened before?\" (simple spatial smoothing, no predictors)\n\n```{r kde-baseline}\n#| message: false\n\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n```{r visualize-kde}\n#| fig-width: 8\n#| fig-height: 6\n\nggplot() +\n  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"KDE Value\",\n    option = \"plasma\"\n  ) +\n  labs(\n    title = \"Kernel Density Estimation Baseline\",\n    subtitle = \"Simple spatial smoothing of burglary locations\"\n  ) +\n  theme_crime()\n```\n\n## 6.2: Generate Final Predictions\n\n```{r final-predictions}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ countDarkalleys + dark_alleys.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n\n## 6.3: Compare Model vs. KDE Baseline\n\n```{r compare-models}\n#| fig-width: 12\n#| fig-height: 4\n\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n```{r model-comparison-metrics}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n### Based on the above results the Kernel Density Model performs better than the model in terms of both MAE and RMSE. The KDE model is purely spatial and does not take into account predictors of burglaries. The negative binomial model shows the relationship between proximity to dark alleys and burglaries, but does not capture the spatial geometry of burglaries as well.\n\n## 6.4: Where Does the Model Work Well? Where are the largest errors?\n\n```{r prediction-errors}\n#| fig-width: 10\n#| fig-height: 5\n\n# Calculate errors\nfishnet <- fishnet %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"magma\") +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2\n```\n\n### This step maps the negative binomial model's errors. This is useful to see if their are spatial patterns in the errors. The graphic shows that the model overpredicted burglaries in certain northern and southern areas. It underpredicted burglaries especially in the northern and eastern boundaries of the city.\n\n## 6.5 Model Summary Table\n\n```{r model-summary-table}\n# Create nice summary table\nmodel_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%\n  mutate(\n    across(where(is.numeric), ~round(., 3))\n  )\n\nmodel_summary %>%\n  kable(\n    caption = \"Final Negative Binomial Model Coefficients (Exponentiated)\",\n    col.names = c(\"Variable\", \"Rate Ratio\", \"Std. Error\", \"Z\", \"P-Value\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  footnote(\n    general = \"Rate ratios > 1 indicate positive association with burglary counts.\"\n  )\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"embed-resources":true,"output-file":"lab4code_final.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Lab Assignment 4: Spatial Predictive Analysis","subtitle":"MUSA 5080 - Fall 2025","author":"Annalise Abraham","date":"today","editor":"visual","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}